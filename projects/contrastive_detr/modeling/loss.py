from typing import Any
import torch
import torch.nn as nn
import torch.nn.functional as F
from utils.math import calc_iou
from torchvision.ops import sigmoid_focal_loss
from einops import repeat, rearrange

##############################################################################################################
# Localization Loss
##############################################################################################################


def l1_loss(anchors: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
    """ calculate the l1 loss between anchors and targets
    Args:
        anchors: (M, 2) the predicted anchors
        targets: (M, 2) the ground truth targets
    
    Returns:
        loss: scalar
    """
    return torch.abs(anchors - targets).mean()


def iou_loss(anchors: torch.Tensor, targets: torch.Tensor, iou="giou") -> torch.Tensor:
    """ minimize the IoU between anchors and targets
    Args:
        anchors: (M, 2) the predicted anchors
        targets: (M, 2) the ground truth targets
        iou: the type of iou, can be "iou" or "giou"
    Returns:
        loss: scalar
    """
    iou_gt = calc_iou(anchors, targets, type=iou)
    return 1-iou_gt.mean()


def iou_loss_reg(pred_iou: torch.Tensor,
                 anchors: torch.Tensor,
                 targets: torch.Tensor,
                 iou="giou",
                 reg_loss="focal") -> torch.Tensor:
    """ minimize the difference between the predicted IoU and the ground truth IoU
    Here iou loss means the regression loss between the predicted IoU and the ground truth IoU
    Args:
        pred_iou: (M, 1) the predicted IoU
        anchors: (M, 2) the predicted anchors
        targets: (M, 2) the ground truth targets
        iou: the type of iou, can be "iou" or "giou"

    Returns:
        loss: scalar
    """
    iou_gt = calc_iou(anchors, targets, type=iou)
    if reg_loss == "focal":
        loss = sigmoid_focal_loss(pred_iou, iou_gt, alpha=0.5, gamma=2.0, reduction="mean")
    elif reg_loss == "bce":
        loss = F.binary_cross_entropy(pred_iou, iou_gt, reduction="mean")
    else:
        raise NotImplementedError("reg_loss should be focal or bce")

    return loss


##############################################################################################################
# Contrastive Loss
##############################################################################################################


def matching_cross_entropy(vid_feats: torch.Tensor, txt_feats: torch.Tensor, label_vid2txt: torch.Tensor,
                           label_txt2vid: torch.Tensor) -> torch.Tensor:
    """ calculate the contrastive loss between video features and text features
    Args:
        vid_feats: (N, D) the video features
        txt_feats: (N, D) the text features
        label_vid2txt: (N, ) the label mapping for video to text
        label_txt2vid: (N, ) the label mapping for text to video
        Both of label_vid2txt and label_txt2vid are generated by matcher
    Returns:
        loss: scalar
    """
    # calculate the cosine similarity between video features and text features
    sim = F.cosine_similarity(vid_feats, txt_feats, dim=-1)  # (B, N, N)
    # calculate the loss
    vid_loss = F.cross_entropy(input=rearrange(sim, "b nv nt -> (b nv) nt"),
                               target=rearrange(label_vid2txt, "b nv -> (b nv)"))
    txt_loss = F.cross_entropy(input=rearrange(sim, "b nv nt -> (b nt) nv"),
                               target=rearrange(label_txt2vid, "b nt -> (b nt)"))
    loss = 0.5 * (vid_loss + txt_loss)

    return loss
